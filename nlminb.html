<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
 <html><head><title>R: Optimization using PORT routines</title>
 <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 <link rel="stylesheet" type="text/css" href="R.css">
 </head><body>
 
 <table width="100%" summary="page for nlminb"><tr><td>nlminb</td><td align="right">R Documentation</td></tr></table>
 
 <h2>Optimization using PORT routines </h2>
 
 <h3>Description</h3>
 
 
 <p>Unconstrained and constrained optimization using PORT routines.
 </p>
 
 
 <h3>Usage</h3>
 
 <pre>
 nlminb(start, objective, gradient = NULL, hessian = NULL, ...,
        scale = 1, control = list(), lower = -Inf, upper = Inf)
 </pre>
 
 
 <h3>Arguments</h3>
 
 
 <table summary="R argblock">
 <tr valign="top"><td><code>start</code></td>
 <td>
 
 <p>numeric vector, initial values for the parameters to be optimized.
 </p>
 </td></tr>
 <tr valign="top"><td><code>objective</code></td>
 <td>
 
 <p>Function to be minimized.  Must return a scalar value (possibly
 NA/Inf).  The first argument to <code>objective</code> is the vector of
 parameters to be optimized, whose initial values are supplied
 through <code>start</code>.  Further arguments (fixed during the course of
 the optimization) to <code>objective</code> may be specified as well (see
 <code>...</code>).
 </p>
 </td></tr>
 <tr valign="top"><td><code>gradient</code></td>
 <td>
 
 <p>Optional function that takes the same arguments as <code>objective</code> and
 evaluates the gradient of <code>objective</code> at its first argument.  Must
 return a vector as long as <code>start</code>.
 </p>
 </td></tr>
 <tr valign="top"><td><code>hessian</code></td>
 <td>
 
 <p>Optional function that takes the same arguments as <code>objective</code> and
 evaluates the hessian of <code>objective</code> at its first argument.  Must
 return a square matrix of order <code>length(start)</code>.  Only the
 lower triangle is used.
 </p>
 </td></tr>
 <tr valign="top"><td><code>...</code></td>
 <td>
 <p>Further arguments to be supplied to <code>objective</code>.</p>
 </td></tr>
 <tr valign="top"><td><code>scale</code></td>
 <td>
 <p>See PORT documentation (or leave alone).</p>
 </td></tr>
 <tr valign="top"><td><code>control</code></td>
 <td>
 <p>A list of control parameters. See below for details.</p>
 </td></tr>
 <tr valign="top"><td><code>lower, upper</code></td>
 <td>
 
 <p>vectors of lower and upper bounds, replicated to be as long as
 <code>start</code>.  If unspecified, all parameters are assumed to be
 unconstrained.
 </p>
 </td></tr>
 </table>
 
 
 <h3>Details</h3>
 
 
 <p>Any names of <code>start</code> are passed
 on to <code>objective</code> and where applicable, <code>gradient</code> and
 <code>hessian</code>.  The parameter vector will be coerced to double.
 </p>
 <p>The PORT documentation is at
 <a href="http://netlib.bell-labs.com/cm/cs/cstr/153.pdf">http://netlib.bell-labs.com/cm/cs/cstr/153.pdf</a>.
 </p>
 
 
 <h3>Value</h3>
 
 
 <p>A list with components:
 </p>
 <table summary="R valueblock">
 <tr valign="top"><td><code>par</code></td>
 <td>
 <p>The best set of parameters found.</p>
 </td></tr>
 <tr valign="top"><td><code>objective</code></td>
 <td>
 <p>The value of <code>objective</code> corresponding to <code>par</code>.</p>
 </td></tr>
 <tr valign="top"><td><code>convergence</code></td>
 <td>
 <p>An integer code. <code>0</code> indicates successful
 convergence.
 </p>
 </td></tr>
 <tr valign="top"><td><code>message</code></td>
 <td>
 
 <p>A character string giving any additional information returned by the
 optimizer, or <code>NULL</code>. For details, see PORT documentation.
 </p>
 </td></tr>
 <tr valign="top"><td><code>iterations</code></td>
 <td>
 <p>Number of iterations performed.</p>
 </td></tr>
 <tr valign="top"><td><code>evaluations</code></td>
 <td>
 <p>Number of objective function and gradient function evaluations</p>
 </td></tr>
 </table>
 
 
 <h3>Control parameters</h3>
 
 
 <p>Possible names in the <code>control</code> list and their default values
 are:
 </p>
 
 <dl>
 <dt><code>eval.max</code></dt><dd><p>Maximum number of evaluations of the objective
 function allowed.  Defaults to 200.</p>
 </dd></dl>
 
 <dl>
 <dt><code>iter.max</code></dt><dd><p>Maximum number of iterations allowed.
 Defaults to 150.</p>
 </dd></dl>
 
 <dl>
 <dt><code>trace</code></dt><dd><p>The value of the objective function and the parameters
 is printed every trace'th iteration.  Defaults to 0 which
 indicates no trace information is to be printed.</p>
 </dd>
 <dt><code>abs.tol</code></dt><dd><p>Absolute tolerance.  As from <font face="Courier New,Courier" color="#666666"><b>R</b></font> 2.12.0, defaults
 to 0 so the absolute convergence test is not used.  If the objective
 function is known to be non-negative, the previous default of
 <code>1e-20</code> would be more appropriate.</p>
 </dd></dl>
 
 <dl>
 <dt><code>rel.tol</code></dt><dd><p>Relative tolerance.  Defaults to
 <code>1e-10</code>.</p>
 </dd></dl>
 
 <dl>
 <dt><code>x.tol</code></dt><dd><p>X tolerance.  Defaults to <code>1.5e-8</code>.</p>
 </dd></dl>
 
 <dl>
 <dt><code>xf.tol</code></dt><dd><p>false convergence tolerance.  Defaults to
 <code>2.2e-14</code>.</p>
 </dd></dl>
 
 <dl>
 <dt><code>step.min, step.max</code></dt><dd><p>Minimum and maximum step size.  Both
 default to <code>1.</code>.</p>
 </dd></dl>
 
 <dl>
 <dt>sing.tol</dt><dd><p>singular convergence tolerance; defaults to
 <code>rel.tol</code>.</p>
 </dd></dl>
 
 <dl>
 <dt>scale.init</dt><dd><p>...</p>
 </dd></dl>
 
 <dl>
 <dt>diff.g</dt><dd><p>an estimated bound on the relative error in the
 objective function value.</p>
 </dd></dl>
 
 
 
 
 <h3>Author(s)</h3>
 
 
 <p>(of <font face="Courier New,Courier" color="#666666"><b>R</b></font> port) Douglas Bates and Deepayan Sarkar.
 </p>
 
 
 <h3>References</h3>
 
  <p><a href="http://netlib.bell-labs.com/netlib/port/">http://netlib.bell-labs.com/netlib/port/</a> </p>
 
 
 <h3>See Also</h3>
 
 
 <p><code>optim</code> and <code>nlm</code>.
 </p>
 <p><code>optimize</code> for one-dimensional minimization and
 <code>constrOptim</code> for constrained optimization.
 </p>
 
 
 <h3>Examples</h3>
 
 <pre>
 x &lt;- rnbinom(100, mu = 10, size = 10)
 hdev &lt;- function(par) {
     -sum(dnbinom(x, mu = par[1], size = par[2], log = TRUE))
 }
 nlminb(c(9, 12), hdev)
 nlminb(c(20, 20), hdev, lower = 0, upper = Inf)
 nlminb(c(20, 20), hdev, lower = 0.001, upper = Inf)
 
 ## slightly modified from the S-PLUS help page for nlminb
 # this example minimizes a sum of squares with known solution y
 sumsq &lt;- function( x, y) {sum((x-y)^2)}
 y &lt;- rep(1,5)
 x0 &lt;- rnorm(length(y))
 nlminb(start = x0, sumsq, y = y)
 # now use bounds with a y that has some components outside the bounds
 y &lt;- c( 0, 2, 0, -2, 0)
 nlminb(start = x0, sumsq, lower = -1, upper = 1, y = y)
 # try using the gradient
 sumsq.g &lt;- function(x,y) 2*(x-y)
 nlminb(start = x0, sumsq, sumsq.g,
        lower = -1, upper = 1, y = y)
 # now use the hessian, too
 sumsq.h &lt;- function(x,y) diag(2, nrow = length(x))
 nlminb(start = x0, sumsq, sumsq.g, sumsq.h,
        lower = -1, upper = 1, y = y)
 
 ## Rest lifted from optim help page
 
 fr &lt;- function(x) {   ## Rosenbrock Banana function
     x1 &lt;- x[1]
     x2 &lt;- x[2]
     100 * (x2 - x1 * x1)^2 + (1 - x1)^2
 }
 grr &lt;- function(x) { ## Gradient of 'fr'
     x1 &lt;- x[1]
     x2 &lt;- x[2]
     c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),
        200 *      (x2 - x1 * x1))
 }
 nlminb(c(-1.2,1), fr)
 nlminb(c(-1.2,1), fr, grr)
 
 
 flb &lt;- function(x)
     { p &lt;- length(x); sum(c(1, rep(4, p-1)) * (x - c(1, x[-p])^2)^2) }
 ## 25-dimensional box constrained
 ## par[24] is *not* at boundary
 nlminb(rep(3, 25), flb,
           lower=rep(2, 25),
           upper=rep(4, 25))
 ## trying to use a too small tolerance:
 r &lt;- nlminb(rep(3, 25), flb, control = list(rel.tol=1e-16))
 stopifnot(grepl("rel.tol", r$message))
 </pre>
 
 
 </body></html>
