<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
 <html><head><title>R: Agglomerative Nesting (Hierarchical Clustering)</title>
 <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 <link rel="stylesheet" type="text/css" href="R.css">
 </head><body>
 
 <table width="100%" summary="page for agnes"><tr><td>agnes</td><td align="right">R Documentation</td></tr></table>
 
 <h2>Agglomerative Nesting (Hierarchical Clustering)</h2>
 
 <h3>Description</h3>
 
 
 <p>Computes agglomerative hierarchical clustering of the dataset.
 </p>
 
 
 <h3>Usage</h3>
 
 <pre>
 agnes(x, diss = inherits(x, "dist"), metric = "euclidean",
       stand = FALSE, method = "average", par.method,
       keep.diss = n &lt; 100, keep.data = !diss)
 </pre>
 
 
 <h3>Arguments</h3>
 
 
 <table summary="R argblock">
 <tr valign="top"><td><code>x</code></td>
 <td>
 
 <p>data matrix or data frame, or dissimilarity matrix, depending on the
 value of the <code>diss</code> argument.
 </p>
 <p>In case of a matrix or data frame, each row corresponds to an observation,
 and each column corresponds to a variable. All variables must be numeric.
 Missing values (NAs) are allowed.
 </p>
 <p>In case of a dissimilarity matrix, <code>x</code> is typically the output of
 <code>daisy</code> or <code>dist</code>.
 Also a vector with length n*(n-1)/2 is allowed (where n is the number
 of observations), and will be interpreted in the same way as the
 output of the above-mentioned functions. Missing values (NAs) are not
 allowed.
 </p>
 </td></tr>
 <tr valign="top"><td><code>diss</code></td>
 <td>
 
 <p>logical flag: if TRUE (default for <code>dist</code> or
 <code>dissimilarity</code> objects), then <code>x</code> is assumed to be a
 dissimilarity matrix.  If FALSE, then <code>x</code> is treated as
 a matrix of observations by variables.
 </p>
 </td></tr>
 <tr valign="top"><td><code>metric</code></td>
 <td>
 
 <p>character string specifying the metric to be used for calculating
 dissimilarities between observations.
 The currently available options are &quot;euclidean&quot; and &quot;manhattan&quot;.
 Euclidean distances are root sum-of-squares of differences, and
 manhattan distances are the sum of absolute differences.
 If <code>x</code> is already a dissimilarity matrix, then this argument will
 be ignored.
 </p>
 </td></tr>
 <tr valign="top"><td><code>stand</code></td>
 <td>
 
 <p>logical flag: if TRUE, then the measurements in <code>x</code> are
 standardized before calculating the dissimilarities. Measurements
 are standardized for each variable (column), by subtracting the
 variable's mean value and dividing by the variable's mean absolute
 deviation.  If <code>x</code> is already a dissimilarity matrix, then this
 argument will be ignored.
 </p>
 </td></tr>
 <tr valign="top"><td><code>method</code></td>
 <td>
 
 <p>character string defining the clustering method.  The six methods
 implemented are &quot;average&quot; ([unweighted pair-]group average method, UPGMA),
 &quot;single&quot; (single linkage), &quot;complete&quot; (complete linkage),
 &quot;ward&quot; (Ward's method), &quot;weighted&quot; (weighted average linkage) and
 its generalization <code>"flexible"</code> which uses (a constant version of)
 the Lance-Williams formula and the <code>par.method</code> argument.  Default
 is &quot;average&quot;.
 </p>
 </td></tr>
 <tr valign="top"><td><code>par.method</code></td>
 <td>
 <p>if <code>method == "flexible"</code>, numeric vector of
 length 1, 3, or 4, see in the details section.
 </p>
 </td></tr>
 <tr valign="top"><td><code>keep.diss, keep.data</code></td>
 <td>
 <p>logicals indicating if the dissimilarities
 and/or input data <code>x</code> should be kept in the result.  Setting
 these to <code>FALSE</code> can give much smaller results and hence even save
 memory allocation <EM>time</EM>.</p>
 </td></tr>
 </table>
 
 
 <h3>Details</h3>
 
 
 <p><code>agnes</code> is fully described in chapter 5 of Kaufman and Rousseeuw (1990).
 Compared to other agglomerative clustering methods such as <code>hclust</code>,
 <code>agnes</code> has the following features: (a) it yields the
 agglomerative coefficient (see <code>agnes.object</code>)
 which measures the amount of clustering structure found; and (b)
 apart from the usual tree it also provides the banner, a novel
 graphical display (see <code>plot.agnes</code>).
 </p>
 <p>The <code>agnes</code>-algorithm constructs a hierarchy of clusterings.<br>
 At first, each observation is a small cluster by itself.  Clusters are
 merged until only one large cluster remains which contains all the
 observations.  At each stage the two <EM>nearest</EM> clusters are combined
 to form one larger cluster.
 </p>
 <p>For <code>method="average"</code>, the distance between two clusters is the
 average of the dissimilarities between the points in one cluster and the
 points in the other cluster.
 <br>
 In <code>method="single"</code>, we use the smallest dissimilarity between a
 point in the first cluster and a point in the second cluster (nearest
 neighbor method).
 <br>
 When <code>method="complete"</code>, we use the largest dissimilarity
 between a point in the first cluster and a point in the second cluster
 (furthest neighbor method).
 </p>
 <p>The <code>method = "flexible"</code> allows (and requires) more details:
 The Lance-Williams formula specifies how dissimilarities are
 computed when clusters are agglomerated (equation (32) in K.\&amp;R.,
 p.237).  If clusters <i>C_1</i> and <i>C_2</i> are agglomerated into a
 new cluster, the dissimilarity between their union and another
 cluster <i>Q</i> is given by
 </p>
 <p align="center"><i>
     D(C_1 \cup C_2, Q) = &alpha;_1 * D(C_1, Q) + &alpha;_2 * D(C_2, Q) +
                          &beta; * D(C_1,C_2) + &gamma; * |D(C_1, Q) - D(C_2, Q)|,
   </i></p>
 
 <p>where the four coefficients <i>(&alpha;_1, &alpha;_2, &beta;, &gamma;)</i>
 are specified by the vector <code>par.method</code>:
 </p>
 <p>If <code>par.method</code> is of length 1,
 say <i>= &alpha;</i>, <code>par.method</code> is extended to
 give the &ldquo;Flexible Strategy&rdquo; (K. \&amp; R., p.236 f) with
 Lance-Williams coefficients <i>(&alpha;_1 = &alpha;_2 = &alpha;, &beta; =
     1 - 2&alpha;, &gamma;=0)</i>.<br>
 If of length 3, <i>&gamma; = 0</i> is used.
 </p>
 <p><B>Care</B> and expertise is probably needed when using <code>method
     = "flexible"</code> particularly for the case when <code>par.method</code> is
 specified of longer length than one.
 The <EM>weighted average</EM> (<code>method="weighted"</code>) is the same as
 <code>method="flexible", par.method = 0.5</code>.
 </p>
 
 
 <h3>Value</h3>
 
 
 <p>an object of class <code>"agnes"</code> (which extends <code>"twins"</code>)
 representing the clustering.  See <code>agnes.object</code> for
 details, and methods applicable.
 </p>
 
 
 <h3>BACKGROUND</h3>
 
 
 <p>Cluster analysis divides a dataset into groups (clusters) of
 observations that are similar to each other.
 </p>
 
 <dl>
 <dt>Hierarchical methods</dt><dd><p>like
 <code>agnes</code>, <code>diana</code>, and <code>mona</code>
 construct a hierarchy of clusterings, with the number of clusters
 ranging from one to the number of observations.</p>
 </dd>
 <dt>Partitioning methods</dt><dd><p>like
 <code>pam</code>, <code>clara</code>, and <code>fanny</code>
 require that the number of clusters be given by the user.</p>
 </dd>
 </dl>
 
 
 
 <h3>References</h3>
 
 
 <p>Kaufman, L. and Rousseeuw, P.J. (1990).
 <EM>Finding Groups in Data: An Introduction to Cluster Analysis</EM>.
 Wiley, New York.
 </p>
 <p>Anja Struyf, Mia Hubert &amp; Peter J. Rousseeuw (1996)
 Clustering in an Object-Oriented Environment.
 <EM>Journal of Statistical Software</EM> <B>1</B>.
 <a href="http://www.jstatsoft.org/v01/i04">http://www.jstatsoft.org/v01/i04</a>
 </p>
 <p>Struyf, A., Hubert, M. and Rousseeuw, P.J. (1997). Integrating
 Robust Clustering Techniques in S-PLUS,
 <EM>Computational Statistics and Data Analysis</EM>, <B>26</B>, 17&ndash;37.
 </p>
 <p>Lance, G.N., and W.T. Williams (1966).
 A General Theory of Classifactory Sorting Strategies, I. Hierarchical
 Systems.
 <EM>Computer J.</EM> <B>9</B>, 373&ndash;380.
 </p>
 
 
 <h3>See Also</h3>
 
 
 <p><code>agnes.object</code>, <code>daisy</code>, <code>diana</code>,
 <code>dist</code>, <code>hclust</code>, <code>plot.agnes</code>,
 <code>twins.object</code>.
 </p>
 
 
 <h3>Examples</h3>
 
 <pre>
 data(votes.repub)
 agn1 &lt;- agnes(votes.repub, metric = "manhattan", stand = TRUE)
 agn1
 plot(agn1)
 
 op &lt;- par(mfrow=c(2,2))
 agn2 &lt;- agnes(daisy(votes.repub), diss = TRUE, method = "complete")
 plot(agn2)
 agnS &lt;- agnes(votes.repub, method = "flexible", par.meth = 0.6)
 plot(agnS)
 par(op)
 
 ## Exploring the dendrogram structure
 (d2 &lt;- as.dendrogram(agn2)) # two main branches
 d2[[1]] # the first branch
 d2[[2]] # the 2nd one  { 8 + 42  = 50 }
 d2[[1]][[1]]# first sub-branch of branch 1 .. and shorter form
 identical(d2[[c(1,1)]],
           d2[[1]][[1]])
 ## a "textual picture" of the dendrogram :
 str(d2)
 
 data(agriculture)
 
 ## Plot similar to Figure 7 in ref
 ## Not run: plot(agnes(agriculture), ask = TRUE)
 
 </pre>
 
 
 </body></html>
